<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Well</title>
    <link>https://tmhm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml</link>
    <description>Recent content in 机器学习 on Well</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-EN</language>
    <managingEditor>wells217@163.com (Well)</managingEditor>
    <webMaster>wells217@163.com (Well)</webMaster>
    <copyright>(c) 2017 Well.</copyright>
    <atom:link href="https://tmhm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>统计学习笔记（0）</title>
      <link>https://tmhm.github.io/2016/04/20/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B00/</link>
      <pubDate>Wed, 20 Apr 2016 15:26:00 +0000</pubDate>
      <author>wells217@163.com (Well)</author>
      <guid>https://tmhm.github.io/2016/04/20/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B00/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;监督学习 （supervised learning）&lt;/li&gt;
&lt;li&gt;非监督学习 （unsupervised learning）&lt;/li&gt;
&lt;li&gt;半监督学习 （semi-supervised learning）&lt;/li&gt;
&lt;li&gt;强化学习 （reinforcement learning）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;一直以为强化学习不属于统计学习的范畴，看来过去臆想了。&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;监督学习基本概念&#34;&gt;监督学习基本概念&lt;/h3&gt;

&lt;h4 id=&#34;输入-特征-输出空间&#34;&gt;输入、特征、输出空间&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;输入与输出的所有值分别称之为&lt;strong&gt;输入空间&lt;/strong&gt;和&lt;strong&gt;输出空间&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;所有特征向量存在的空间称为&lt;strong&gt;特征空间&lt;/strong&gt;，特征空间的每一维对应于一个特征；&lt;/li&gt;
&lt;li&gt;有时，输入空间会和特征空间一致；有时会不同，输入空间往往会经过某些变换将输入空间映射到特征空间；&lt;/li&gt;
&lt;li&gt;模型实际是都是定义在特征空间上的；&lt;/li&gt;
&lt;li&gt;人们根据输入和输出变量的不同类型来*区分不同的预测任务*：

&lt;ul&gt;
&lt;li&gt;输入和输出均为连续变量的预测问题称之为&lt;strong&gt;回归问题&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;输出为有限个离散变量的预测问题称之为&lt;strong&gt;分类问题&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;输入和输出均为变量序列的预测问题称之为&lt;strong&gt;标注问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;联合概率分布&#34;&gt;联合概率分布&lt;/h4&gt;

&lt;p&gt;监督学习假设输入和输出遵循联合概率分布$P(X,Y)$.&lt;/p&gt;

&lt;h4 id=&#34;假设空间&#34;&gt;假设空间&lt;/h4&gt;

&lt;p&gt;监督学习的目的在于学习一个有输入到输出的映射，这一映射由模型来表示。
模型属于由输入空间到输出空间的映射的集合，这一集合就是&lt;strong&gt;假设空间（hypothesis space）&lt;/strong&gt;，假设空间的确定意味着学习范围的确定。&lt;/p&gt;

&lt;p&gt;监督学习的模型可以是概率模型或非概率模型，用条件概率分布或决策函数表示。&lt;/p&gt;

&lt;h4 id=&#34;问题形式化&#34;&gt;问题形式化&lt;/h4&gt;

&lt;p&gt;监督学习分学习和预测两个过程。学习过程是利用训练数据集学习一个模型，再用学习到的模型对测试样本进行预测，即预测过程。&lt;/p&gt;

&lt;p&gt;一个具体的模型$y=f(x)$,对一个输入$x_i$,可以产生一个输出$f(x_i)$,而训练模型中对应的输出是$y_i$,如果这个模型训练的足够好，有很好的预测能力，则其训练样本的输出$y_i$和模型的输出$f(x_i)$之间的差就应该足够小。学习系统就是通过不断尝试，选取最好的模型，以便对训练数据集具有最好的预测，同时对未知的测试数据集的预测也有尽可能好的推广，即泛化能力。&lt;/p&gt;

&lt;h3 id=&#34;统计学习三要素&#34;&gt;统计学习三要素&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;模型

&lt;ul&gt;
&lt;li&gt;模型的假设空间包含所有可能的条件概率或决策函数&lt;/li&gt;
&lt;li&gt;参数空间&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;策略
（学习的准则）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;损失函数和风险函数&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;0-1、 平方、 绝对、 对数损失函数&lt;/li&gt;
&lt;li&gt;损失函数的期望，即平均意义下的损失，称之为风险函数或期望损失&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;经验风险最小化与结构风险最小化&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;经验最小化的策略认为经验最小的模型是最优的，当样本数量很小时会出现“过拟合”&lt;/li&gt;
&lt;li&gt;结构最小化是为了防止“过拟合”提出，其等价于正则化。结构风险在经验风险上加上表示模型复杂度的正则项或者惩罚项&lt;/li&gt;
&lt;li&gt;$\frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i)) +\lambda \ast J(f)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;$J(f)$为模型的复杂度，模型越复杂，复杂度越大，即复杂度表示了对复杂模型的惩罚，$\lambda$系数 大于0， 用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;统计学习问题归结为最优化问题&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;模型的评估与模型选择&#34;&gt;模型的评估与模型选择&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;一般考虑到&lt;strong&gt;训练误差&lt;/strong&gt;和&lt;strong&gt;测试误差&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;避免过拟合&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;正则化与交叉验证&#34;&gt;正则化与交叉验证&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;正则项一般有1-范数和2-范数&lt;/li&gt;

&lt;li&gt;&lt;p&gt;交叉验证&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;简单交叉验证，即随机将已知数据分2部分，分别作为训练和测试，然后将训练集在各种参数条件下训练，最后在测试集上评估，选出测试误差最小的模型；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;S折交叉验证，首先随机将数据切分为S个互不相交的大小相同的子集，然后用S-1个子集用于训练，余下的作为测试，重复选择S次，最后选择S次测试中平均测试误差最小的模型&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;留一交叉验证，S折交叉验证的特殊情形S=N，N为给定数据集的容量，即每次只有一个数据样本用于测试。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;泛化能力&#34;&gt;泛化能力&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;即模型对未知数据的预测能力。&lt;/li&gt;
&lt;li&gt;理论上可以通过泛化误差上界的大小来进行分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;生成模型与判别模型&#34;&gt;生成模型与判别模型&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;根据采用的方式是生成方法和判别方法而来。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成方法&lt;/strong&gt;是由数据学习联合概率分布，然后求得条件概率分布作为模型
    * 典型有：朴素贝叶斯法和隐马尔科夫模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;判别方法&lt;/strong&gt;是由数据直接学习决策函数或者条件概率分布作为模型
    * 典型有：K近邻，感知机，决策树，逻辑回归，最大熵模型，SVM，提升方法（AdaBoost），条件随机场等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;区别：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;生成方法可以还原出联合概率分布，判别则不行；&lt;/li&gt;
&lt;li&gt;生成方法学习的收敛速度更快&lt;/li&gt;
&lt;li&gt;当存在隐变量，仍可以用生成方法，而此时判别方法行不通&lt;/li&gt;
&lt;li&gt;判别方法直接学习条件概率或决策函数，直接预测，往往学习的准确率更高；由于直接学习，可以对数据进行各种程度上的抽象、定义特征并使用特征，也可以简化学习问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;面向问题&#34;&gt;面向问题&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;分类问题&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;指标:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TP&amp;ndash;将正类分为正的；&lt;/li&gt;
&lt;li&gt;FN&amp;ndash;将正类分为负的；&lt;/li&gt;
&lt;li&gt;FP&amp;ndash;将负类分为正的；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;TN&amp;ndash;将负类分为负的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;精确率 P = TP/(TP+FP)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;召回率 R = TP/(TP+FN)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;以上两者的调和均值 2/F = 1/P + 1/R&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;标注问题&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;回归问题&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一元回归和多元回归&lt;/li&gt;
&lt;li&gt;线性和非线性&lt;/li&gt;
&lt;li&gt;常用损失函数&amp;ndash;平方损失函数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;非监督学习&#34;&gt;非监督学习&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;数据没有类别信息，也不给定目标值&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&#34;典型代表&#34;&gt;典型代表：&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;聚类&lt;/strong&gt;将数据集合分成由类似的对象组成的多个类&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;密度估计&lt;/strong&gt;用于寻找数据统计值&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;降维&lt;/strong&gt;，用于展示数据或者预处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;e.g&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;K-均值&lt;/li&gt;
&lt;li&gt;最大期望算法&lt;/li&gt;
&lt;li&gt;DBSCAN(Density-based spatial clustering of applications with noise)&lt;/li&gt;
&lt;li&gt;Parzen窗设计&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;统计学习方法，李航
机器学习实战， Peter Harrington&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>