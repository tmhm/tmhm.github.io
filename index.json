[{"content":"学而时习之，不亦说乎? \u0026mdash;《论语》\n2024 The mom test 俞军 产品方法论 长安的荔枝 科学，无尽的前沿 了不起的我：自我发展的心理学 华为没有成功，只有成长：任正非传 腾讯传 教父三部曲（已完成前2部） 小岛经济学 谁动了我的奶酪 战争论 哈佛幸福课（泛读） 沟通的方法（脱不花） 2023 Systems archetype basics: from story to structure 华为访谈录2 毛选 提问的力量 提问的艺术：为什么你该这么问 影响力 战争论 有限与无限的游戏 增长黑客 百年孤独 创新者的窘境（re.） 打造真正的新产品 幕后产品：打造突破式产品思维 认识商业 纳瓦尔宝典 认知觉醒 相约星期二 置身事内 积极心理学（哈佛公开课） 计算广告：互联网商业变现的市场和技术 CEO说：人人都应该像企业家一样思考 我的伯父周恩来 佛畏系统 系统之美 Bert 基础教程：Transformer 大模型实战 六神磊磊读金庸 2022 吴军数学通识讲义 系统之美(-ing) 启示录（打造用户喜爱的产品） 动物农场 创新者的方法 有毒的逻辑：为何有说服力的话反而不可信 终身成长 狭路相逢勇者胜-任正非 谈判 箭术与禅心 沟通的方法 腾讯传 遥远的救世主 孩子：挑战 乌合之众 不抱怨的世界 成为乔布斯 2021 产品为王：移动游戏产品设计规则 林宾华著 本质：真正厉害的人都是直击本质的高手 Python高性能编程 深度学习推荐系统 王喆著 态度改变和社会影响 如何成为讲话有趣的人 打胜战的思想/打胜战的策略/打胜战的团队，共3册 好战略，坏战略 调查分析。分析形势，认清竞争优势和态势，了解竞争对手 指导方针。为了克服障碍而制定整体性策略 连贯性动作。采取统一连贯性的动作 游戏化思维：改变未来商业的新力量 系统之美 少有人走的路：心智成熟的旅程 毛泽东选集（1～4） 重看 批判性思维 华为访谈录（活生生的一步创业史） 写给大家看的设计书 刷新（重新发现商业与未来） 家庭成长的磨难成就其同理心，感同身受 成长型思维 同理心+共同的价值观+安全可靠=信任 文化的开放，3c同心环：文化-\u0026gt;能力-\u0026gt;概念。跟ios，google，aws等的开放合作 人与机器的差异性：同理心，教育，创造力，判断和问责 疫情隔离，让我想到了同理心，有的hr不太懂得同理心，比较直板的执行命令，而让员工的情绪更加激化 吴军数学通识讲义 穷查理宝典 相约星期二（用爱生活） 如何成为讲话有趣的人 蛤蟆先生去看心理医生 沸腾新十年：移动互联网丛林里的勇敢穿越者 2020 社会性动物 游戏改变世界 格局:世界永远不缺聪明人 揭秘深度强化学习 白话强化学习与pytorch 万历十五年 硅谷钢铁侠 埃隆马斯克 四步创业法 卓有成效的管理者 学会提问，跟批判性思维很多相似观点 2019 kubernetes 权威指南 Kafka 权威指南 （泛读） RabbitMQ 实战 (泛读) 非暴力沟通 高效人士的七个习惯 苹果 - 后乔布斯时代 原则（生活和工作 - Ray Dalio） 如何阅读一本书 写给大家看的设计书 领域驱动设计 (DDD) 代码整洁之道 重构 Reinforcement Learning: An Introduction, 2nd 将心注入（重读） 2018 未来简史 稻盛和夫 - 阿米巴经营 拒绝平庸 - 周鸿祎和他的创士记 俞敏洪口述: 在痛苦的世界中尽力而为 Python 核心编程 (泛读) SRE Google 运维解密（泛读） 数据科学家养成手册 (泛读) 微服务设计 数据架构 - 大数据、数据仓库以及Data Vault Redis 实战 Machine Learning yearning, Andrew Ng 深度学习 (花书) Tensorflow Serving 部分源码 \u0026hellip; 2017 Google 未来之镜 创新者的窘境 人月神话 设计心理学 Caffe 1.0 源码 \u0026hellip; 2016 历史的教训 硅谷之谜 文明之光 facebook 马克 扎克伯格传记：后乔布斯时代的传奇 弘一大师新传 三体（未完成，过半后，吸引力下降, 勿喷） 微软的梦工厂（一口气读完了） 数学之美（第二版） 富爸爸穷爸爸 人类简史 智能时代（吴军著） C++语言的设计与演化 数据结构与算法分析（C语言描述）缺代码实现 统计学习方法. 李航 控制系统设计指南（第三版） 嵌入式Linux系统使用开发（主要包括完成linux系统，c/c++的回顾，多线程等） Just for fun - Linus Torvalds自传[中文版] 机器学习实践（泛读） 机器学习.周志华（泛读） 算法（第四版）. Robert Sedgewick（-ing，看进去以后，相见恨晚） Reinforcement learning: An induction. Richard S. Sutton, First edition（-ing） 无人驾驶车辆模型预测控制.北京理工大学出版社（泛读） 2015 硅谷之火 浪潮之巅 天才在左疯子在右 从0到1 生命咖啡馆 黑客与画家 奇思妙想：15位计算机天才及其重大发现 乔布斯传 平凡的世界（三部全） 一只iphone的全球旅行 C++ Primer（中文第五版）匆忙过了一遍，未实现代码。 ios 游戏开发：创意与实现 Linux 内核设计的艺术 (课程) PyBrain 部分源码 ","permalink":"http://localhost:61312/posts/reading_list/","summary":"\u003cp\u003e学而时习之，不亦说乎?    \u0026mdash;《论语》\u003c/p\u003e","title":"阅读书单"},{"content":"有关Pandas 分组聚合相关操作的一些总结，包括groupby分组, transform, 以及explode等操作。\nexplode 爆炸函数 初始化的DataFrame df = pd.DataFrame({\u0026#39;A\u0026#39;: [\u0026#34;a,b,c\u0026#34;, \u0026#34;b\u0026#34;, [\u0026#34;a\u0026#34;, \u0026#34;e\u0026#34;]], \u0026#39;B\u0026#39;: [1, 2, 3]}) df A B 0\ta,b,c\t1 1\tb\t2 2\t[a, e]\t3 explode函数， 默认将列表数据炸开，分成多行，并且index 保持不变 df=df.explode(\u0026#34;A\u0026#34;) df A\tB 0\ta,b,c\t1 1\tb\t2 2\ta\t3 2\te\t3 同样可以把类列表的文字炸开 df.set_index([\u0026#34;B\u0026#34;]).apply(lambda x: x.str.split(\u0026#34;,\u0026#34;)).explode(\u0026#34;A\u0026#34;).reset_index() # 另一种assign的实现 # df2= df.assign(A=df.A.str.split(\u0026#39;,\u0026#39;)).explode(\u0026#39;A\u0026#39;).reset_index(drop=True) A\tB 0\ta\t1 1\tb\t1 2\tc\t1 3\tb\t2 4\ta\t3 5\te\t3 groupby分组以及transform 分组，使用transform対每组取使用第一个出现的值 df2[\u0026#34;B\u0026#34;] = df2.groupby(\u0026#34;A\u0026#34;)[\u0026#34;B\u0026#34;].transform(\u0026#34;first\u0026#34;) df2 A B 0\ta\t1 1\tb\t1 2\tc\t1 3\tb\t1 4\ta\t1 5\te\t3 对列数据进行ID编码 对A列中出现的值进行ID化编码(常规做法) from sklearn.preprocessing import LabelEncoder le = LabelEncoder() df2[\u0026#39;ID1\u0026#39;] = le.fit_transform(df2[\u0026#39;A\u0026#39;]) # 获取map le_mapping = dict(zip(le.classes_, le.transform(le.classes_))) le_mapping {\u0026#39;a\u0026#39;: 0, \u0026#39;b\u0026#39;: 1, \u0026#39;c\u0026#39;: 2, \u0026#39;e\u0026#39;: 3} ID编码的高性能版(当map的数量万级以上时，可明显看到速度差距) c= df2.A.astype(\u0026#34;category\u0026#34;) d = dict(enumerate(c.cat.categories)) map2 = {v: k for k, v in d.items()} map2 {\u0026#39;a\u0026#39;: 0, \u0026#39;b\u0026#39;: 1, \u0026#39;c\u0026#39;: 2, \u0026#39;e\u0026#39;: 3} df2[\u0026#34;ID2\u0026#34;] = c.map(map2) # output A\tB\tID1\tID2 0\ta\t1\t0\t0 1\tb\t1\t1\t1 2\tc\t1\t2\t2 3\tb\t1\t1\t1 4\ta\t1\t0\t0 5\te\t3\t3\t3 ","permalink":"http://localhost:61312/posts/pandas_group/","summary":"\u003cp\u003e有关Pandas 分组聚合相关操作的一些总结，包括groupby分组, transform, 以及explode等操作。\u003c/p\u003e","title":"Pandas分组聚合及编码"},{"content":"把个人站点从wordpress 迁移到了hugo+even。 本文主要记录hugo 下搭配使用even 主题的一些配置\n修改even 主图的icon 可以将之前做好的512x512图片传到这个工具网站favivon，自动生成多个尺度的icon 照片, 然后下载下来，解压到主题的目录 themes/even/static/.\nHugo 常用命令 创建新的文章 hugo new post/new_blog.md\n生成网页预览，可使用Chrome 无痕模式查看 http://localhost:1313/\nhugo server 生成静态网页，然后将public 文件夹推到网站地址\nhugo cp -r public/* SITE_PATH ","permalink":"http://localhost:61312/posts/wordpress2hugo/","summary":"\u003cp\u003e把个人站点从wordpress 迁移到了hugo+even。\n本文主要记录hugo 下搭配使用even 主题的一些配置\u003c/p\u003e","title":"Wordpress2Hugo"},{"content":" Thanks to all the collaborators I\u0026rsquo;ve worked with. ☺\nLi, Q., Xia, W. etc. Privileged Knowledge State Distillation for Reinforcement Learning-based Educational Path Recommendation, KDD24. Accepted Liu, Y., Xia, W.*, Liu, W., Zhu, M., Zhang, W., Tang, R., \u0026amp; Yu, Y. (2024, May). HiFI: Hierarchical Fairness-aware Integrated Ranking with Constrained Reinforcement Learning. In Companion Proceedings of the ACM on Web Conference 24(pp. 196-205). Li, Q., Xia, W., Yin, L. A., Shen, J., Rui, R., Zhang, W., \u0026hellip; \u0026amp; Yu, Y. (2023, October). Graph Enhanced Hierarchical Reinforcement Learning for Goal-oriented Learning Path Recommendation. In Proceedings of the 32nd ACM CIKM 23 (pp. 1318-1327). Wang, H., Long, T., Yin, L., Zhang, W., Xia, W., Hong, Q., \u0026hellip; \u0026amp; Yu, Y. (2023, August). GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized Adaptive Testing. In Proceedings of the 29th ACM SIGKDD 23 (pp. 2279-2289). Zhu, M., Xia, W.*, Liu, W., Liu, Y., Tang, R., \u0026amp; Zhang, W. (2023, April). Integrated Ranking for News Feed with Reinforcement Learning. In Companion Proceedings of the ACM Web Conference 23 (pp. 480-484). Chen, X., Shen, J., Xia, W., Jin, J., Song, Y., Zhang, W., \u0026hellip; \u0026amp; Yu, Y. (2023, February). Set-to-Sequence Ranking-based Concept-aware Learning Path Recommendation. AAAI 23 (pp. 5027–5035). Pan, L., Qian, J., Xia, W., Mao, H., Yao, J., Li, P., \u0026amp; Xiao, Z. (2022, November). Optimizing communication in deep reinforcement learning with XingTian. In Proceedings of the 23rd ACM/IFIP International Middleware Conference (pp. 255-268). Xia, W., Liu, W., Liu, Y., \u0026amp; Tang, R. (2022, October). Balancing Utility and Exposure Fairness for Integrated Ranking with Reinforcement Learning. In Proceedings of the 31st ACM CIKM 2022 (pp. 4590-4594). He, Z., Xia, W.*, Dong, K., Guo, H., Tang, R., Xia, D., \u0026amp; Zhang, R. (2022, August). Unsupervised learning style classification for learning path generation in online education platforms. In Proceedings of the 28th ACM SIGKDD 22 (pp. 2997-3006). Long, T., Qin, J., Shen, J., Zhang, W., Xia, W., Tang, R., \u0026hellip; \u0026amp; Yu, Y. (2022, February). Improving knowledge tracing with collaborative information. In Proceedings of the fifteenth ACM WSDM 22 (pp. 599-607). Xia, W., Li, H., \u0026amp; Li, B. (2016, December). A control strategy of autonomous vehicles based on deep reinforcement learning. In 2016 9th International Symposium on Computational Intelligence and Design (ISCID) (Vol. 2, pp. 198-201). IEEE. 夏伟, 李慧云. 基于深度强化学习的自动驾驶策略学习方法[J]. 集成技术, 2017(3). 于2023年入选《学术精要数据库》近10年的“三高”论文（高PCSI、高引用和高下载，top 1%） ","permalink":"http://localhost:61312/publications/","summary":"Thanks to all the collaborators I\u0026rsquo;ve worked with. ☺\nLi, Q., Xia, W. etc. Privileged Knowledge State Distillation for Reinforcement Learning-based Educational Path Recommendation, KDD24. Accepted Liu, Y., Xia, W.*, Liu, W., Zhu, M., Zhang, W., Tang, R., \u0026amp; Yu, Y. (2024, May). HiFI: Hierarchical Fairness-aware Integrated Ranking with Constrained Reinforcement Learning. In Companion Proceedings of the ACM on Web Conference 24(pp. 196-205). Li, Q., Xia, W., Yin, L. A.","title":"Selected Publications"},{"content":"强化学习概述，从问题定义，到分类，以及经典开源库。\nRL问题回顾 强化学习（Reinforcement Learning）本身可以定义为一个广泛的学习问题，学会找到状态（Situation）到动作（Actions）的一个映射关系，以最大化一个数值型的回报（Reward）信号。一个完整的强化学习问题可以用马氏决策过程中的最优控制理论来进行描述。在马氏链中，当前时刻的状态（State） 仅仅与上一时刻的状态有关。如下图1所示，一个智能体（Agent）可以通过某种方式感受环境的状态（State），然后可以通过某一个动作（Action）来改变环境的下一状态。在这个不断交互的过程中，Agent还必须具有一个或者以上的、与此环境状态相关的目标（Goal）。\n与RL问题相对应的任何求解方法，可以称之为一个强化学习方法。\n1. RL的两个重要特征 试错搜索（trial-and-error） 延迟回报（delayed reward） 可以引出与监督学习的重要区别——评价的方式不同。 监督学习中通过正确的指示（instruct）来进行反馈；强化学习是依靠整个生命周期所选择的动作来进行评价式的反馈。\n2. RL系统中的四大主要元素（element） 策略（Policy） 定义某个时刻agent的行为，可以看做策略的映射$\\pi_(s_t)$。粗略地说，一个策略可以看做是接收到状态到智能体做出动作的一种映射关系，可以用函数或者表的形式来表现。通常来说，策略可以是确定的，也可能是随机的，即可以用条件概率来表示。\n奖励/回报函数（Reward function） 奖励函数定义了强化学习问题中的目标。它把当前每个状态（或者状态-动作对）映射到一个评价数值，以表现该Agent当前所做事件的好坏程度。\n值函数（Value function） 奖励函数所表现出的是当前状态或者状态-动作对的立即评价，值函数表征的是对长远意义下的评判。 $V_s$表示当前状态$s$下的累积回报；$V_{(s,a)}$表示当前状态$s$下，执行动作$a$下的累积回报。\n粗略来说，值函数可以表示从当前状态开始到未来（long-term），Agent可以收获到奖励的一种累积和。即值函数是对Agent整个生命周期的一种评价。值函数是动作选择的一个标准。\n环境的模型（model of the environment） 即对该Agent生存环境的行为模仿（mimics the behavior of the environment）。举一个例子，给定一个状态和动作，环境模型可以预测相对应的下一状态和奖励。如果模型已知，强化学习问题可以演化为动态规划问题求解。\n3. RL中智能体学习方法的分类 根据强化学习问题中所含元素的种类，其Agent的学习方法，可以分为5大类。\nModel-free Model-based Actor-critic (Policy + Value function) Policy-based Value-based 4. 探索与利用的权衡 Trade-off between exploration and exploitation\nAgent 需要根据已知的状态、动作和回报的相关信息，来不断获得最大的回报，即利用（exploit）当前已知的知识；另外，Agent 需要探索（explore）一些未知的知识，以期望在未来实现更好的动作。（由于目前的知识往往并不是最优的）\n因此，在RL中，利用与探索是一个权衡的话题，目前已提出多种方法来尝试解决这个问题。\nϵ-greedy action selection（以小概率不贪心的选择方式） Softmax action selection（基于Gibbs分布或者称之为玻尔兹曼分布，以概率选择动作） $$ \\cfrac{e^{Q_t(a)/\\tau}}{\\sum_{b=1}^n e^{Q_t(b)/\\tau}} $$\nτ\u0026gt;0表示温度（temperature）, 高的温度，选择动作近乎平等；温度趋近0的时候，此法接近于贪心选择。\n5. Framework/Platform OpenAI gym 是强化学习研究领域广泛使用的一个经典工具包，它主要包含两部分：\nEnvironments，经典问题的测试集，并提供统一的接口； /ScoreBoards/LeaderBoards/Benchmarking，用户算法性能对比的平台，用户可以通过api分享其算法的结果 Rllab 与gym 完全兼容，并内置了一些RL的算法，目前rllab项目已停止更新。\ngarage是基于rllab 而来，该项目是为了benchmarking 连续动作控制场景下的DRL算法而建立。\nTensorforce: A TensorFlow library for applied reinforcement learning\nRay/RLlib 目前RL应用领域sota的框架，构建remote特性；1）具备ms级的task响应，2）以及million的吞吐量。\nIntel Coach is a python reinforcement learning research framework containing implementation of many state-of-the-art algorithms.\nOpenAi Baselines SOTA RL算法的集合\nRefernece Sutton R S, Barto A G. Reinforcement learning: An introduction[M]. Slides, David Silver. Lecture 1: Introduction to Reinforcement Learning. ","permalink":"http://localhost:61312/posts/rl_basic/","summary":"\u003cp\u003e强化学习概述，从问题定义，到分类，以及经典开源库。\u003c/p\u003e","title":"强化学习问题回顾"},{"content":"实验室深度学习服务器环境配置ubuntu14.04 \u0026amp;\u0026amp; GTX1080 \u0026amp;\u0026amp; Cuda8.0, 解决安装驱动后桌面重复登录问题。 前面部分是配置ubuntu cuda 环境的记录，后面方案部分是成功安装驱动+桌面的正解。 问题的焦点在于：安装cuda驱动后，登录不了桌面，停留在重复输入密码界面。\n博文中分析的结论： 虚拟机中不能直接调用物理显卡进行 CUDA 编程；虚拟机中运行 CUDA 需要硬件和软件的配合才能使用，对于一般使用者可能暂时不太可能的。\n参考博文：\n深度学习主机环境配置: Ubuntu16.04+Nvidia GTX 1080+CUDA8.0\n深度学习主机环境配置: Ubuntu16.04+GeForce GTX 1080+TensorFlow\nubuntu14.04+cuda8.0（GTX1080）+caffe安装\n如何搭建一台深度学习服务器\nCtrl+alt+F1进入字符界面，关闭图形界面\nsudo service lightdm stop //必须有，不然会安装失败 sudo /etc/init.d/lightdm stop //一样的命令 sudo chmod 755 NVIDIA-Linux-x86_64-367.27.run //获取权限 sudo ./NVIDIA-Linux-x86_64-367.27.run //安装驱动 Accept Continue installation 安装完成之后\nsudo service lightdm start\n图形界面出现，然后关机，由让人重复输入密码，登录不了\n博主说\n$ sudo /etc/init.d/gdm stop $ sudo nvidia-installer --update $ sudo /etc/init.d/gdm start 升级到375版本， 还是没用，启动进入不了桌面，重复登录\nInstall driver 367 Uninstall previous nvidia drivers.\n$ sudo apt-get purge nvidia-* Stop light gdm (graphical interface)\n$ sudo service lightgdm Go to tty (CTRL+ALT+F1). Set your init state to 3 (text only mode). It is important to do this. Note these commands on a paper or something. I experienced sometimes the tty does not show with the newest driver. I just ssh to my PC as a way around.\n$ sudo init 3 Log in to tty and cd to the directory where your have downloaded the driver.\n$ sudo ./NVIDIA-Linux-x86_64-367.35.run It will ask if you want to install 32-bit libraries, say no (assuming you do not have a 32-bit OS, hopefully. If you do have a 32-bit OS it is a good idea to upgrade…)\nIn a few minutes it is done….smooth. Reboot your PC $ sudo reboot update 之后还是不能进 图形界面\nUninstall previous nvidia drivers.\nsudo apt-get purge nvidia-* sudo apt-get autoremove sudo apt-get --purge remove nvidia-* remove 之后，\nnvidia-smi 还是能看到gpu的。why？\n卸载不了？\nsudo apt-get install nvidia-prime $ sudo /etc/init.d/lightdm stop $ sudo nvidia-installer --update $ sudo /etc/init.d/lightdm start 升级到375版本， 还是没用，启动进入不了桌面，重复登录\n有人说，安装必须要在安装桌面前安装GTX 1080 driver，后面方案验证来看， 那个参数才是关键。\n解决方法 利用sudo gedit /etc/modprobe.d/blacklist-nouveau.conf新建blacklist-nouveau.conf文件，输入命令\nblacklist nouveau blacklist lbm-nouveau options nouveau modeset=0 alias nouveau off alias lbm-nouveau off 保存并退出。这一步是为了禁掉Ubuntu自带开源驱动nouveau。之后sudo reboot重启系统。在终端执行命令 lsmod | grep nouveau 查看nouveau模块是否被加载。如果什么都没输出，则执行下一步。\n根本问题在于 参数： \u0026ndash;no-opengl-files\nsudo /etc/init.d/lightdm stop sudo ./NVIDIA-Linux-x86_64-375.20.run --no-opengl-files sudo /etc/init.d/lightdm start 即可以正常登录界面了！！\n在安装过程中的选项：\nAccept\nContinue installation\nregister the kernel moudle sources with DKMS?\nNO\nWould you like to run the nvidia-xconfig utility to automatically update your X Configuration file so set the NVIDIA X driver will be used when you restart X?\nNO\nInstall 32-Bit compatibility libraries?参考\nNO Cuda8.0安装 运行\nsudo sh cuda_8.0.44_linux.run 选项如下所示：\nDescription This package includes over 100+ CUDA examples that demonstrate various CUDA programming principles, and efficient CUDA implementation of algorithms in specific application domains. The NVIDIA CUDA Samples License Agreement is available in Do you accept the previously read EULA? accept/decline/quit: accept Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 367.48? (y)es/(n)o/(q)uit: n Install the CUDA 8.0 Toolkit? (y)es/(n)o/(q)uit: y Enter Toolkit Location [ default is /usr/local/cuda-8.0 ]: Do you want to install a symbolic link at /usr/local/cuda? (y)es/(n)o/(q)uit: y Install the CUDA 8.0 Samples? (y)es/(n)o/(q)uit: y Enter CUDA Samples Location [ default is /home/c302 ]: Installing the CUDA Toolkit in /usr/local/cuda-8.0 ... Installing the CUDA Samples in /home/c302 ... Copying samples to /home/c302/NVIDIA_CUDA-8.0_Samples now... Finished copying samples. =========== = Summary = =========== Driver: Not Selected Toolkit: Installed in /usr/local/cuda-8.0 Samples: Installed in /home/c302 Please make sure that - PATH includes /usr/local/cuda-8.0/bin - LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-8.0/bin Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-8.0/doc/pdf for detailed information on setting up CUDA. ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 8.0 functionality to work. To install the driver using this installer, run the following command, replacing \u0026lt;CudaInstaller\u0026gt; with the name of this run file: sudo \u0026lt;CudaInstaller\u0026gt;.run -silent -driver Logfile is /tmp/cuda_install_9045.log 设置环境变量 export PATH=/usr/local/cuda-8.0/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH 添加系统变量修改到系统文件 sudo vi /etc/profile 在最后添加上面两句，然后保存。使立即生效 sudo ldconfig //环境变量立即生效 验证 cuda c302@c302-dl:~/Downloads$ nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Sun_Sep__4_22:14:01_CDT_2016 Cuda compilation tools, release 8.0, V8.0.44 测试cuda的samples cd ‘/home/zhou/NVIDIA_CUDA-8.0_Samples’ make //这里需要点时间 最后显示：\nmake[1]: Leaving directory `/home/c302/NVIDIA_CUDA-8.0_Samples/7_CUDALibraries/MersenneTwisterGP11213'\nFinished building CUDA samples\ncd 0_Simple/matrixMul\n运行测试如下：\nc302@c302-dl:~/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMul$ ./matrixMul [Matrix Multiply Using CUDA] - Starting... GPU Device 0: \u0026#34;GeForce GTX 1080\u0026#34; with compute capability 6.1 MatrixA(320,320), MatrixB(640,320) Computing result using CUDA Kernel... done Performance= 1109.06 GFlop/s, Time= 0.118 msec, Size= 131072000 Ops, WorkgroupSize= 1024 threads/block Checking computed result for correctness: Result = PASS NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled. 下一篇将会是安装cuDNN、tensorflow等lib\n","permalink":"http://localhost:61312/posts/dl_server_ubuntu14_cuda8_gtx1080/","summary":"\u003cp\u003e实验室深度学习服务器环境配置ubuntu14.04 \u0026amp;\u0026amp;  GTX1080 \u0026amp;\u0026amp; Cuda8.0, 解决安装驱动后桌面重复登录问题。\n前面部分是配置ubuntu cuda 环境的记录，后面方案部分是成功安装驱动+桌面的正解。\n问题的焦点在于：安装cuda驱动后，登录不了桌面，停留在重复输入密码界面。\u003c/p\u003e","title":"DL服务器主机环境配置 ubuntu14.04 \u0026\u0026 Cuda8.0"},{"content":"C++中的一些小知识点。包括：printf压栈顺序，指针引用，动态内存以及变量的存储位置，构造函数，this指针等问题的回顾\nc中的printf函数 main() { int b = 3; int arr[]= {6,7,8,9,10}; int * ptr = arr; *(ptr++) += 123; printf(\u0026#34;%d,%d\\n\u0026#34;,*ptr,*(++ptr)); return 0; } 输出 ：8,8\n原因：printf函数计算参数是从右往左压栈的\nc和c++的关系 c++ 语言支持函数重载，c语言不支持函数重载； 函数在C++编译后在库中的名字和C语言的不同，假设某个函数原型是void foo（int x， int y）。该函数被C编译器编译后，在库中的名字是_foo,而在C++编译器中则会产生像_foo_int_int之类的名字。 C++提供了C连接交换指定符 extern \u0026ldquo;c\u0026rdquo; 解决名字匹配的问题。 指针和引用 区别：\n非空区别，在任何情况下都不能使用指向空值的引用。一个引用必须总是指向某些对象； 合法性，在使用引用之前不需要测试它的合法性，相反，指针则应该总是被测试，防止其为空； 可修改区别，指针可被重新赋值以指向另一个不同对象。但是引用则总是指向在初始化被指定的对象，以后不能改变，但是指向的对象的其内容可以改变 应用区别，有存在不指向任何对象的可能和不同时刻会指向不同的对象等情况时，使用指针；如果总是指向一个对象并且指向一个对象以后就不会改变指向，那么应该使用引用。 传递动态内存 void swap3(int *p, int *q) { int *tmp; tmp = p; p = q; q = tmp;//仅仅交换了指针的值，并没有改变两块内存的值 } void swap4(int *p, int *q) { int tmp; tmp = *p; //获取p指向内存的值 *p = *q; *q = tmp; } void swap5(int \u0026amp;p, int \u0026amp;q) { int tmp; tmp = p; //获取p指向内存的值 p = q; q = tmp; } //\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nint t1 = 1,t2 = 2; cout \u0026lt;\u0026lt; t1 \u0026lt;\u0026lt; \u0026#34;\u0026#34;\u0026lt;\u0026lt; t2 \u0026lt;\u0026lt; endl; swap3(\u0026amp;t1,\u0026amp;t2); //仅仅交换了指针的值，并没有改变两块内存的值 cout \u0026lt;\u0026lt; t1 \u0026lt;\u0026lt; \u0026#34;\u0026#34;\u0026lt;\u0026lt; t2 \u0026lt;\u0026lt; endl; // 后面两个函数分别用指针和引用交换成功 swap4(\u0026amp;t1,\u0026amp;t2); cout \u0026lt;\u0026lt; t1 \u0026lt;\u0026lt; \u0026#34;\u0026#34;\u0026lt;\u0026lt; t2 \u0026lt;\u0026lt; endl; swap5(t1,t2); cout \u0026lt;\u0026lt; t1 \u0026lt;\u0026lt; \u0026#34;\u0026#34;\u0026lt;\u0026lt; t2 \u0026lt;\u0026lt; endl; malloc 申请内存 void getMemory_err(char *p, int num) { p = (char *)malloc(sizeof(char )* num); // 没有return 指针，不能传递动态内存 } //返回指针变量 char *pGetMemory(char *p, int num) { p = (char *)malloc(sizeof(char )* num); return p; } // 用指针的指针， void getMemory(char **p, int num) { *p = (char *)malloc(sizeof(char )* num); } //\u0026mdash;\u0026mdash;\nchar *str = NULL; getMemory(\u0026amp;str,10); strcpy(str,\u0026#34;hello\u0026#34;); char *str2 = NULL; str2 = pGetMemory(str2,10); strcpy(str2,\u0026#34;test\u0026#34;); cout\u0026lt;\u0026lt; *str \u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; cout\u0026lt;\u0026lt; \u0026amp;str \u0026lt;\u0026lt; endl; cout\u0026lt;\u0026lt; *str2 \u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt; str2 \u0026lt;\u0026lt; endl; cout\u0026lt;\u0026lt; \u0026amp;str2 \u0026lt;\u0026lt; endl; output:\nh hello 012FF774 t test 012FF768 字符串变量存储问题 int a = 0; //全局初始化区 char *p1; //全局未初始化区 int _tmain(int argc, _TCHAR* argv[]) { int b; //栈 char s[] = \u0026#34;abc\u0026#34;; //s在栈上， 常量区会存储一份\u0026#34;abc\\0\u0026#34;，用于共享，s[]初始化的时候拷贝过来放到栈上 char *p2; //栈 char *p3 = \u0026#34;123456\u0026#34;; //123456\\0在常量区，p3在栈上。 const char *m = \u0026#34;123456\u0026#34;; //m在栈上， “123456” 在常量区 static int c =0; //全局（静态）初始化区 p1 = (char *)malloc(10); p2 = (char *)malloc(20); //分配得来得10和20字节的区域就在堆区。 strcpy(p1, \u0026#34;123456\u0026#34;); //123456\\0放在常量区，编译器可能会将它与p3所指向的\u0026#34;123456\u0026#34; 优化成一个地方。 cout \u0026lt;\u0026lt; (m == p3 ? 1: 0) \u0026lt;\u0026lt; endl; // out 1, cout \u0026lt;\u0026lt; (p1 == p3? 1: 0) \u0026lt;\u0026lt; endl; // out 0; cout \u0026lt;\u0026lt; p1 \u0026lt;\u0026lt; \u0026#34;———\u0026#34; \u0026lt;\u0026lt; p3 \u0026lt;\u0026lt; endl; // out 123456---123456 return 0; } //\u0026mdash;\nchar *strA() { char str[] = \u0026#34;hello world\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;in str[] \u0026#34;\u0026lt;\u0026lt;endl; cout \u0026lt;\u0026lt; \u0026#34;before: \u0026#34;\u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; str[0] = \u0026#39;t\u0026#39;; cout \u0026lt;\u0026lt;\u0026#34;After:\u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; return str; } char *pStrA_err() { char *str = \u0026#34;hello world\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;in *str \u0026#34;\u0026lt;\u0026lt;endl; cout \u0026lt;\u0026lt; \u0026#34;before: \u0026#34;\u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; //*str = \u0026#39;P\u0026#39;; // !!!!!!------runtime error 字符串常量保存在只读数据段 cout \u0026lt;\u0026lt;\u0026#34;After:\u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; return str; } char *pStrA(){ static char *str = \u0026#34;hello world\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;in *str \u0026#34;\u0026lt;\u0026lt;endl; cout \u0026lt;\u0026lt; \u0026#34;before: \u0026#34;\u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; //*str = \u0026#39;P\u0026#39;; // !!!!!!------runtime error ,字符串常量保存在只读数据段 cout \u0026lt;\u0026lt;\u0026#34;After:\u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; return str; } main:\nchar *c = strA(); char *c2 = pStrA_err(); char *c3 = pStrA(); cout \u0026lt;\u0026lt; \u0026#34;After fun return:\u0026#34; \u0026lt;\u0026lt; \u0026#34;--c:\u0026#34; \u0026lt;\u0026lt; c \u0026lt;\u0026lt; \u0026#34;--c2:\u0026#34; \u0026lt;\u0026lt; c2 \u0026lt;\u0026lt; \u0026#34;--c3\u0026#34; \u0026lt;\u0026lt; c3 \u0026lt;\u0026lt; endl; output:\nin str[] before: hello world After:tello world in *str before: hello world After:hello world in *str before: hello world After:hello world After fun return:--c:@?--c2:hello world--c3hello world 结论：\n字符串数据保存在常量区，只读的数据段，不能直接修改 函数内数组是局部变量，在函数内通过str[0] 可以修改。return之后，局部变量释放， 构造函数 class tA{ public: int _a; tA(){ _a = 1; } void print(){ printf(\u0026#34;%d\u0026#34;,_a); } }; class tB :public tA{ public: int _a; tB(){ _a = 2; } }; //\u0026ndash;\ntB b; tB b; b.print(); // 在构造B类之前，先调用A的构造函数，在A类中_a =1, printf(\u0026#34;%d\u0026#34;,b._a); // B类中 _a = 2; return 0; output: 12\n在构造B类之前，先调用A的构造函数\nmalloc/free ＆＆new/delete malloc/free 是c++/c语言的标准库函数，new/delete是c++的运算符，它们都可以用于申请和释放动态内存 由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能执行构造函数和析构函数 c++语言中new运算符， 能完成动态内存分配和初始化工作； delete 运算符完成清理和释放内存工作 指针和句柄 句柄和指针其实是两个截然不同的概念。 windows系统用句柄标记系统资源，隐藏系统的信息，它是一个32bit的uint。 指针则标记某个物理内存的地址 句柄可以看做是指向指针的指针。 this 指针 本质上是一个函数参数，只是编译器隐藏起形式，语法层面的参数，this指针只能在成员函数中使用，全局函数，静态函数都不能使用this指针。 在python中直接显性给出 this指针在成员函数的开始前构造，在成员的结束后清除 this指针并不占用对象的空间， 只会占用参数传递时的栈空间，或者直接占用一个寄存器 this指针会因编译器不同而有不同的存放位置，可能是堆，栈，也可能是寄存器。 this指针只有在成员函数中才有定义。因此，在获得一个对象后，也不能通过对象使用this指针。所以，我们无法知道一个对象的this指针的位置（只有在成员函数中才有this指针的位置） “=”和“\u0026lt;=” 的优先级 1.( (file_got_len = recv_str(sock,buf,BUF_SIZE) ) \u0026lt;= 0)\n2.( file_got_len = recv_str(sock,buf,BUF_SIZE) \u0026lt;= 0 )\n第二种情况下，当recv_str()函数成功返回发送字符串的时候，尽管会成功返回发送字节数大于0，\n但是，file_got_len只会返回0，\n因为“\u0026lt;=”的优先级大于“=”。\n所以在多语句写在一起时，最好用（） 明示！！\n运算操作符 int i,t; t = (i=1)+(++i); 输出 t= 4 i首先被赋值1，随后++i，使i的值变为2，到做加法的操作的时候，两个操作数都要读i此时的值，结果是两个2相加，等于4.\n其汇编程序（基于vs2010），如下：\nint i,t; t = (i=1)+(++i); 011413FE mov dword ptr [i],1 01141405 mov eax,dword ptr [i] 01141408 add eax,1 0114140B mov dword ptr [i],eax 0114140E mov ecx,dword ptr [i] 01141411 add ecx,dword ptr [i] 01141414 mov dword ptr [t],ecx i自加后，只保留在eax 寄存器里，然后将eax的2赋给i，所以，i 就变成2了。此处和动态语言的引用似乎有所类似。\nsizeof操作符与数组 int t,tt,num; int array[5]; int *p = array; t= sizeof(p); //t =4 t= sizeof(int [5]); // t= 20 tt = sizeof(array); // tt = 20 num = sizeof(array)/sizeof(array[0]); // get the number of array . num =5 开始自以为，数组名不是首地址嘛。 应该是一个指针，然后对指针sizeof ，应该是4 个字节才对，为什么呢？\n此时sizeof的是整个数组，而非首指针。 要学会多查看MSDN，解释如下：\nWhen you apply the sizeof operator to an array identifier, the result is the size of the entire array rather than the size of the pointer represented by the array identifier.\n参考：\n程序员面试宝典（第五版）\n","permalink":"http://localhost:61312/posts/c_cplus_basic0/","summary":"\u003cp\u003eC++中的一些小知识点。包括：printf压栈顺序，指针引用，动态内存以及变量的存储位置，构造函数，this指针等问题的回顾\u003c/p\u003e","title":"C_Cplus程序设计涉及的一些知识点"},{"content":"有关PyBrain 库中NFQ算法的流程图分析，包括数据处理和策略的优化pipeline.\nPyBrain库的example之NFQ流程图分析 如下是测试程序。主要分析doEpisode和learn两个函数。\n__author__ = \u0026#39;Thomas Rueckstiess, ruecksti@in.tum.de\u0026#39; from pybrain.rl.environments.cartpole import CartPoleEnvironment, DiscreteBalanceTask, CartPoleRenderer from pybrain.rl.agents import LearningAgent from pybrain.rl.experiments import EpisodicExperiment from pybrain.rl.learners.valuebased import NFQ, ActionValueNetwork #,ActionValueLSTMNetwork from pybrain.rl.explorers import BoltzmannExplorer from numpy import array, arange, meshgrid, pi, zeros, mean from matplotlib import pyplot as plt # switch this to True if you want to see the cart balancing the pole (slower) render = False #True # plt.ion() env = CartPoleEnvironment() if render: renderer = CartPoleRenderer() env.setRenderer(renderer) renderer.start() # balancetask. py inside only used 2 sensors, so here can not use(4,3), just use (2,3) # there is a debug in vesion 0.30, now, new version 0.33 had correct it!! module = ActionValueNetwork(4,3) #(4,3) # 0.33 had correct it #module = ActionValueLSTMNetwork(2,3) task = DiscreteBalanceTask(env, 100) learner = NFQ() learner.explorer.epsilon = 0.4 agent = LearningAgent(module, learner) testagent = LearningAgent(module, None) experiment = EpisodicExperiment(task, agent) def plotPerformance(values, fig): plt.figure(fig.number) plt.clf() plt.plot(values, \u0026#39;o-\u0026#39;) plt.gcf().canvas.draw() performance = [] if not render: pf_fig = plt.figure() #while (True): for _ in xrange(60): #60 # one learning step after one episode of world-interaction!!! experiment.doEpisodes(1) agent.learn(2) # 5 # test performance (these real-world experiences are not used for training) if render: env.delay = True experiment.agent = testagent #r = mean([sum(x) for x in experiment.doEpisodes(5)]) env.delay = False testagent.reset() experiment.agent = agent #performance.append(r) print \u0026#34;update step\u0026#34;, len(performance) #print \u0026#34;reward avg\u0026#34;, r print \u0026#34;explorer epsilon\u0026#34;, learner.explorer.epsilon print \u0026#34;num episodes\u0026#34;, agent.history.getNumSequences() print \u0026#34;update step\u0026#34;, len(performance) if not render: plotPerformance(performance, pf_fig) str = raw_input(\u0026#34;please input sth to end!\u0026#34;) print \u0026#34;you put :\u0026#34;,str experiment.doEpisodes(1) agent.learn(2) 图2的注释2部分，可以参考该博文深度强化学习初探 ,但是他文中的公式应该有点问题。应该把$Q_{m+1}$改为$Q_m$，进一步参考维基百科Q-learning ,如下所示。\n$$ Q_{m+1}(s_t,a_t)=Q_m(s_t,a_t)+α[r_{t+1}+γQ_m(s_{t+1},a_{t+1})−Q_m(s_t,a_t)] $$\n推荐所用的画图软件process on\n用起来挺方便的，在线用谷歌浏览器运行，用户体验挺佳，比visio2010快多了； 可以多用户协作； 目前有一个缺点就是一个框里面的字体格式必须是一样的，不可以修改一个框里面部分的文字的格式。有点类似PS的思想。 ","permalink":"http://localhost:61312/posts/pybrain_example_nfq_code_flow/","summary":"\u003cp\u003e有关PyBrain 库中NFQ算法的流程图分析，包括数据处理和策略的优化pipeline.\u003c/p\u003e","title":"PyBrain库的example之NFQ流程图分析"},{"content":"有关Python中引用特性的一些分析记录，包括对象的初始化，值拷贝等特性。\nprint id.__doc__ ​ id(object) -\u0026gt; integer Return the identity of an object. This is guaranteed to be unique among simultaneously existing objects. (Hint: it\u0026#39;s the object\u0026#39;s memory address.) python中的引用对象特点： python不允许程序员选择采用传值还是传引用。 Python参数传递采用的肯定是“传对象引用”的方式。实际上，这种方式相当于传值和传引用的一种综合。如果函数收到的是一个可变对象（比如字典或者列表）的引用，就能修改对象的原始值——相当于通过“传引用”来传递对象。 如果函数收到的是一个不可变对象（比如数字、字符或者元组）的引用，就不能直接修改原始对象——相当于通过“传值\u0026rsquo;来传递对象。 当人们复制列表或字典时，就复制了对象列表的引用，如果改变引用的值，则修改了原始的参数。 为了简化内存管理，Python通过引用计数机制实现自动垃圾回收功能，Python中的每个对象都有一个引用计数，用来计数该对象在不同场所分别被引用了多少次。每当引用一次Python对象，相应的引用计数就增1，每当消毁一次Python对象，则相应的引用就减1，只有当引用计数为零时，才真正从内存中删除Python对象。 参考 以下是一些例子：\nIn [19]:\n# variable 动态创建一个新的变量，但是，list，tuple，dictionary 却不会创建新的实例 a= 1 b = a print id(a) print id(b) ​ b = 3 print \u0026#34;change b to 3 \u0026#34; print \u0026#34;a: %s, b: %s\u0026#34; %(a ,b) print \u0026#34;a id is : %s; b id is : %s\u0026#34; %(id(a),id(b)) out:\n42295960 42295960 change b to 3 a: 1, b: 3 a id is : 42295960; b id is : 42295912 In [25]:\n# list a= [1,2,3] b = a # 引用 print id(a) print id(b) ​ b[2] = 6 print \u0026#34;change b to 3 \u0026#34; print \u0026#34;a: %s, b: %s\u0026#34; %(a ,b) print \u0026#34;a id is : %s; b id is : %s\u0026#34; %(id(a),id(b)) out：\n66189960 66189960 change b to 3 a: [1, 2, 6], b: [1, 2, 6] a id is : 66189960; b id is : 66189960 In [38]:\n# list a= [1,2,3] b = a[:] # 值拷贝， 创建了新的对象实例 print id(a) print id(b) ​ b[2] = 6 print \u0026#34;change b to 3 \u0026#34; print \u0026#34;a: %s, b: %s\u0026#34; %(a ,b) print \u0026#34;a id is : %s; b id is : %s\u0026#34; %(id(a),id(b)) out：\n65422344 65421832 change b to 3 a: [1, 2, 3], b: [1, 2, 6] a id is : 65422344; b id is : 65421832 In [32]:\n# dictionary a= {\u0026#39;ta\u0026#39;:11,\u0026#39;tb\u0026#39;:22,\u0026#39;tc\u0026#39;:33} b = a # 引用，改变的是原实例的值 print id(a) print id(b) ​ b[\u0026#39;tb\u0026#39;] = 6 print \u0026#34;change b to 3 \u0026#34; print \u0026#34;a: %s,\\n b: %s\u0026#34; %(a ,b) print \u0026#34;a id is : %s;\\n b id is : %s\u0026#34; %(id(a),id(b)) out：\n66214904 66214904 change b to 3 a: {\u0026#39;tb\u0026#39;: 6, \u0026#39;tc\u0026#39;: 33, \u0026#39;ta\u0026#39;: 11}, b: {\u0026#39;tb\u0026#39;: 6, \u0026#39;tc\u0026#39;: 33, \u0026#39;ta\u0026#39;: 11} a id is : 66214904; b id is : 66214904 In [36]:\n# tuple 元组用\u0026#34;()\u0026#34;标识。内部元素用逗号隔开。但是元组不能二次赋值，相当于只读列表。 a= (1,2,3) b = a print id(a) print id(b) ​ # b[0] = 6 print \u0026#34;change b to 3 \u0026#34; print \u0026#34;a: %s,\\n b: %s\u0026#34; %(a ,b) print \u0026#34;a id is : %s;\\n b id is : %s\u0026#34; %(id(a),id(b)) out：\n66132296 66132296 change b to 3 a: (1, 2, 3), b: (1, 2, 3) a id is : 66132296; b id is : 66132296 In [9]:此案例的问题来自博文 ，经改进。如下\ndef add_list(p): pt = p +[5,6] # 1 p = p + [5,6] # 2 1 和2 是等价的，没有将值返回， ‘=’左边的变量，都是函数内部生成的局部临时对象，并没有返回，故不会修改传入参数的值。 # 此处和静态语言的理解方式是一样的。 ​ p1 = [1,2,3] add_list(p1) #1 和2 是等价的，没有改变返回值 print p1 ​ ​ def add_list2(p): p += [5,6] p2 = [1,2,3] add_list2(p2) print p2 out：​\n[1, 2, 3] [1, 2, 3, 5, 6] 此处‘=’号左边的p 应该是一个函数新建的一个局部的、临时的对象实例，等号的右边的p是才是函数传进来的，由于临时的“P”并没有返回，故肯定不会改变传入list的值。此处和静态语言应该是一致的。 所以，它并没有修改原来的p引用。\nIn [6]:\nhelp(\u0026#39;+=\u0026#39;) An augmented assignment expression like \u0026#34;x += 1\u0026#34; can be rewritten as \u0026#34;x = x + 1\u0026#34; to achieve a similar, but not exactly equal effect. In the augmented version, \u0026#34;x\u0026#34; is only evaluated once. Also, when possible, the actual operation is performed *in-place*, meaning that rather than creating a new object and assigning that to the target, the old object is modified instead. In [11]:\n# 字典引用 a = [] b = {\u0026#39;num\u0026#39;:0, \u0026#39;sqrt\u0026#39;:0} resurse = [1,2,3] for i in resurse: b[\u0026#39;num\u0026#39;] = i b[\u0026#39;sqrt\u0026#39;] = i * i a.append(b) print \u0026#34;a: \u0026#34;,a ​ d=[] for i in resurse: b[\u0026#39;num\u0026#39;] = i b[\u0026#39;sqrt\u0026#39;] = i * i d1 = b.copy() d.append(d1) print \u0026#34;d: \u0026#34;,d ​ c=[] for i in resurse: c.append({\u0026#34;num\u0026#34;:i, \u0026#34;sqrt\u0026#34;:i*i}) print \u0026#34;c: \u0026#34;,c out：\n​a: [{\u0026#39;num\u0026#39;: 3, \u0026#39;sqrt\u0026#39;: 9}, {\u0026#39;num\u0026#39;: 3, \u0026#39;sqrt\u0026#39;: 9}, {\u0026#39;num\u0026#39;: 3, \u0026#39;sqrt\u0026#39;: 9}] d: [{\u0026#39;num\u0026#39;: 1, \u0026#39;sqrt\u0026#39;: 1}, {\u0026#39;num\u0026#39;: 2, \u0026#39;sqrt\u0026#39;: 4}, {\u0026#39;num\u0026#39;: 3, \u0026#39;sqrt\u0026#39;: 9}] c: [{\u0026#39;num\u0026#39;: 1, \u0026#39;sqrt\u0026#39;: 1}, {\u0026#39;num\u0026#39;: 2, \u0026#39;sqrt\u0026#39;: 4}, {\u0026#39;num\u0026#39;: 3, \u0026#39;sqrt\u0026#39;: 9}] b[\u0026rsquo;num\u0026rsquo;] = i 和 b[\u0026lsquo;sqrt\u0026rsquo;] = i * i 中的 b[\u0026rsquo;num\u0026rsquo;] 和 b[\u0026lsquo;sqrt\u0026rsquo;] 是已经压入list a 中元素的一个引用，故它可以在不断地改变list 内部变量的值。\n单步调试可以看到，\na中值的变化情况：*以执行完语句a.append(b)为节点 *\n[{\u0026rsquo;num\u0026rsquo;: 1, \u0026lsquo;sqrt\u0026rsquo;: 1}]\n\u0026ndash;\u0026gt; [{\u0026rsquo;num\u0026rsquo;: 2, \u0026lsquo;sqrt\u0026rsquo;: 4},{\u0026rsquo;num\u0026rsquo;: 2, \u0026lsquo;sqrt\u0026rsquo;: 4}]\n\u0026ndash;\u0026gt; [{\u0026rsquo;num\u0026rsquo;: 3, \u0026lsquo;sqrt\u0026rsquo;: 9}, {\u0026rsquo;num\u0026rsquo;: 3, \u0026lsquo;sqrt\u0026rsquo;: 9}, {\u0026rsquo;num\u0026rsquo;: 3, \u0026lsquo;sqrt\u0026rsquo;: 9}]\n在append(b)到list a之前获得b的值拷贝，将值append 到list a 也可以达到目标。如示例d所示。\n​ 当然，示例C是更加简洁的一个版本，这里应该还有迭代器的知识点，暂时还没折腾内部，待到下次和生成器一起分析。\n","permalink":"http://localhost:61312/posts/python_identity/","summary":"\u003cp\u003e有关Python中引用特性的一些分析记录，包括对象的初始化，值拷贝等特性。\u003c/p\u003e","title":"Python 有关引用的一些问题"},{"content":"Python中一些有用的内置函数，包括map，zip，filter，reduce，yield，instance等函数，以及异步IO库asyncio的使用记录\nmap函数 Python实际上提供了一个内置的工具，map函数。这个函数的主要功能是对一个序列对象中的每一个元素应用被传入的函数，并且返回一个包含了所有函数调用结果的一个列表。\nmap?\nDocstring: map(function, sequence[, sequence, ...]) -\u0026gt; list Return a list of the results of applying the function to the items of the argument sequence(s). If more than one sequence is given, the function is called with an argument list consisting of the corresponding item of each sequence, substituting None for missing values when not all sequences have the same length. If the function is None, return a list of the items of the sequence (or a list of tuples if more than one sequence). Type: builtin_function_or_method 下面三个例子参考了该博文 ​ 对可迭代函数\u0026rsquo;iterable\u0026rsquo;中的每一个元素应用‘function’方法，将结果作为list返回。\ndef add100(x): return x+100 hh = [11,22,33] map(add100,hh) Out[2]: [111, 122, 133] 如果给出了额外的可迭代参数，则对每个可迭代参数中的元素‘并行’的应用‘function’。\ndef abc(a, b, c): return a*10000 + b*100 + c ​ list1 = [11,22,33] list2 = [44,55,66] list3 = [77,88,99] map(abc,list1,list2,list3) Out[3]: [114477, 225588, 336699] 如果\u0026rsquo;function\u0026rsquo;给出的是‘None’，自动假定一个‘identity’函数（这个‘identity’不知道怎么解释，看例子吧）\nlist1 = [11,22,33] map(None,list1) Out[5]: [11, 22, 33] list1 = [11,22,33] list2 = [44,55,66] list3 = [77,88,99] map(None,list1,list2,list3) Out[6]: [(11, 44, 77), (22, 55, 88), (33, 66, 99)] zip函数 以下参考了博文\n函式说明：zip(seq1[,seq2 [\u0026hellip;]])-\u0026gt;[(seq1(0),seq2(0)\u0026hellip;,(\u0026hellip;)]。 同时循环两个一样长的函数，返回一个包含每个参数元组对应元素的元组。若不一致，采取截取方式，使得返回的结果元组的长度为各参数元组长度最小值。\nfor x,y in zip([1,2,3],[4,5,6]): print x,y for x,y in zip([1,2,3],[4,5,6]): print x,y 1 4 2 5 3 6 for x,y in zip([1,2,3],[5,6]): print x,y 1 5 2 6 filter函数 filter(bool_func,seq)：此函数的功能相当于过滤器。 调用一个布尔函数bool_func来迭代遍历每个seq中的元素，返回一个使bool_seq返回值为true的元素的序列。\nfilter(lambda x:x%2==0,[1,2,3,4,6,5,7]) Out[15]: [2, 4, 6] reduce函数 reduce(func,seq[,init])：func为二元函数，将func作用于seq序列的元素，每次携带一对（先前的结果以及下一个序列的元素），连续的将现有的结果和下一个值作用在获得的随后的结果上，最后减少我们的序列为一个单一的返回值：如果初始值init给定，第一个比较会是init和第一个序列元素而不是序列的头两个元素。\nreduce(lambda x,y:x+y,[1,2,3,4]) Out[22]: 10 reduce(lambda x,y: x-y,[1,2,3,4,5],19) reduce(lambda x,y: x-y,[1,2,3,4,5],19) Out[23]: 4 reduce(lambda x,y: x-y,[1,2,3,5],5) Out[21]: -6 isinstance isinstance(object, classinfo) 判断一个对象是否是一个已知的类型。\nisinstance(object, class-or-type-or-tuple) -\u0026gt; bool Return whether an object is an instance of a class or of a subclass thereof. With a type as second argument, return whether that is the object\u0026#39;s type. The form using a tuple, isinstance(x, (A, B, ...)), is a shortcut for isinstance(x, A) or isinstance(x, B) or ... (etc.). 其第一个参数为对象，第二个为类型名或类型名的一个列表。其返回值为布尔型。若对象的类型与参数二的类型相同则返回True。若参数二为一个元组，则若对象类型与元组中类型名之一相同即返回True。\ntes = list() tes.append(3) ta= \u0026#39;a\u0026#39;,\u0026#39;b\u0026#39; print tes print isinstance(tes, list) print isinstance(ta, tuple) print isinstance(tes,(int, tuple, list)) print isinstance(tes,(int, tuple)) Out:\n[3] True True True False id 查看object 地址\nin： print id.__doc__\nOut：​ id(object) -\u0026gt; integer\nReturn the identity of an object. This is guaranteed to be unique among simultaneously existing objects. (Hint: it\u0026#39;s the object\u0026#39;s memory address.) assert 断言\nPython中assert用来判断语句的真假，如果为假的时候，将触发AssertionError错误\na = None assert a != None print a out：\nAssertionError Traceback (most recent call last) \u0026lt;ipython-input-1-4165ca7bb901\u0026gt; in \u0026lt;module\u0026gt;() 1 2 a = None ----\u0026gt; 3 assert a != None 4 print a AssertionError: 另一例子：\na=[1,2,3] # a = None assert len(a) \u0026lt; 5 # 为真通过 assert a != None print a out：\n[1, 2, 3] min \u0026amp;\u0026amp; max c = [-10, -45, 0, 5, 3, 50, 15, -20, 25] print \u0026#34;min: %s\u0026#34; %c.index(min(c)) # 返回最小值 print \u0026#34;max: %s\u0026#34; %c.index(max(c)) # 返回最大值 out:\nmin: 1 max: 5 异步IO asyncio 系统含有DNN 算法，需处理大量的数据 避免使用多进程/进程，带来大量切换开销 进程内有http的请求操作（e.g TF-serving 做模型推理)，IO操作频繁 该场景下，协程是一个较好的方案， 将数据的准备和推理并行 可以将多个模型并行推理（后台使用K8s 部署管理tf-serving实例， 进行负载均衡） 示例\nimport time import asyncio import json import functools now = lambda: time.time() async def do_some_work(index, x): sec = 0.5 count = 8 print(\u0026#34;proc-%s, wait sec: %s\u0026#34; % (index, sec)) await asyncio.sleep(sec) return json.dumps({\u0026#34;result\u0026#34;: list([0.5*_i*x for _i in range(count)])}) def callback(t, future): print(\u0026#39;Callback-%s, results: %s\u0026#39; % (t, future.result())) task_num = 5 start = now() tasks = [asyncio.ensure_future(do_some_work(_i, _i)) for _i in range(task_num)] loop = asyncio.get_event_loop() [task.add_done_callback(functools.partial(callback, _index)) for _index, task in enumerate(tasks)] loop.run_until_complete(asyncio.wait(tasks)) for task in tasks: print(\u0026#39;Task ret: \u0026#39;, task.result()) print(\u0026#39;TIME: \u0026#39;, now() - start) REF\n","permalink":"http://localhost:61312/posts/py_builted_func/","summary":"\u003cp\u003ePython中一些有用的内置函数，包括map，zip，filter，reduce，yield，instance等函数，以及异步IO库asyncio的使用记录\u003c/p\u003e","title":"Python内建函数"}]